{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d45542a-f91f-4972-9f49-bbe2af8fcbbf",
   "metadata": {},
   "source": [
    "# Catagorizing and tagging words \n",
    "- nouns verbs and adjectives are usful word classes for many nlp tasks.\n",
    "- they arrive from simple analysis of the dstriubtutions of words in text. \n",
    "- the process of classigying words into their parts of speech and laneling them accordingly is know as part of speech tagging ,  or simply tagging.\n",
    "- parts of speech  are also known as word classes or lexical categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c623310a-5d34-4b92-8b25-14376a7675f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858c1b83-d2de-4e49-be6c-e3de91d474b6",
   "metadata": {},
   "source": [
    "## using a tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bae76fe2-368d-4a37-af2b-8d96cd1f15ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens ['And', 'now', 'for', 'something', 'completely', 'different']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"And now for something completely different\")\n",
    "print('tokens',text)\n",
    "nltk.pos_tag(text)\n",
    "[('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'NN'),\n",
    "('completely', 'RB'), ('different', 'JJ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20396ea5-81f3-44a5-ac00-3a254da1a682",
   "metadata": {},
   "source": [
    "Here we see that and is CC, a coordinating conjunction; now and completely are RB, or adverbs; for is IN, a preposition; something is NN, a noun; and different is JJ, an adjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff543a2-ef0d-490c-9983-62879e5bfc94",
   "metadata": {},
   "source": [
    "# 2 Tagged Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf40400-7469-45e6-b78d-5efdbb3966e0",
   "metadata": {},
   "source": [
    "\n",
    "Tag\tMeaning\tEnglish Examples\n",
    "ADJ\tadjective\tnew, good, high, special, big, local\n",
    "ADP\tadposition\ton, of, at, with, by, into, under\n",
    "ADV\tadverb\treally, already, still, early, now\n",
    "CONJ\tconjunction\tand, or, but, if, while, although\n",
    "DET\tdeterminer, article\tthe, a, some, most, every, no, which\n",
    "NOUN\tnoun\tyear, home, costs, time, Africa\n",
    "NUM\tnumeral\ttwenty-four, fourth, 1991, 14:24\n",
    "PRT\tparticle\tat, on, out, over per, that, up, with\n",
    "PRON\tpronoun\the, their, her, its, my, I, us\n",
    "VERB\tverb\tis, say, told, given, playing, would\n",
    ".\tpunctuation marks\t. , ; !\n",
    "X\tother\tersatz, esprit, dunno, gr8, univeristy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191d1ab6-8455-42c4-8512-49467d98f4a3",
   "metadata": {},
   "source": [
    "# 3 Mapping Words to Properties Using Python Dictionaries\n",
    "- As we have seen, a tagged word of the form (word, tag) is an association between a word and a part-of-speech tag.\n",
    "-  Once we start doing part-of-speech tagging, we will be creating programs that assign a tag to a word, the tag which is most likely in a given context.\n",
    "-  We can think of this process as mapping from words to tags.\n",
    "-  The most natural way to store mappings in Python uses the so-called dictionary data type (also known as an associative array or hash array in other programming languages).\n",
    "-  In this section we look at dictionaries and see how they can represent a variety of language information, including parts of speech.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7b0f6-4736-4860-8024-a80a601039b3",
   "metadata": {},
   "source": [
    "3.2   Dictionaries in Python\n",
    "Python provides a dictionary data type that can be used for mapping between arbitrary types. It is like a conventional dictionary, in that it gives you an efficient way to look things up. However, as we see from 3.1, it has a much wider range of uses.\n",
    "\n",
    "To illustrate, we define pos to be an empty dictionary and then add four entries to it, specifying the part-of-speech of some words. We add entries to a dictionary using the familiar square bracket notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0825f09c-a9a2-4206-8a0a-80cc788eb624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = {}\n",
    "pos['colorless'] = 'ADJ' \n",
    "pos['ideas'] = 'N'\n",
    "pos['sleep'] = 'V'\n",
    "pos['furiously'] = 'ADV'\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c006a5e4-8ab2-4be8-9ef3-64e85cc29a95",
   "metadata": {},
   "source": [
    "# chapter 3.4 ,3.5, 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3c746-1c5a-4d7b-a035-ae280d627db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9b77e70-6d60-4c3b-ae0a-03886e2141c7",
   "metadata": {},
   "source": [
    "# Regular Expressions & Text Normalization (NLTK)\n",
    "## 1. Regular Expressions Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "963de924-95f6-4e70-8b6c-fcc9e1910115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd4148-762e-4a8f-8a98-9808d9cabb72",
   "metadata": {},
   "source": [
    "Meta-characters:\n",
    "| Symbol | Meaning |\n",
    "|--------|---------|\n",
    "| . | Any character |\n",
    "| ^ | Start of string |\n",
    "| $ | End of string |\n",
    "| [abc] | Any character in set |\n",
    "| [A-Z] | Range of characters |\n",
    "| * | 0 or more of previous |\n",
    "| + | 1 or more of previous |\n",
    "| ? | 0 or 1 of previous |\n",
    "| {m,n} | Repeat m to n times |\n",
    "| (a|b) | a or b (disjunction) |\n",
    "| \\ | Escape special character |\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68c0a430-ce38-4ffc-99c0-f5c88fccdffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gold', 'golf', 'hold', 'hole']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words ending with 'ed'\n",
    "[w for w in wordlist if re.search(r'ed$', w)]\n",
    "\n",
    "# Crossword: 8 letters, j=3, t=6\n",
    "[w for w in wordlist if re.search(r'^..j..t..$', w)]\n",
    "\n",
    "# Optional character\n",
    "re.search(r'^e-?mail$', 'email')  # matches 'email' or 'e-mail'\n",
    "\n",
    "# T9 example\n",
    "[w for w in wordlist if re.search(r'^[ghi][mno][jlk][def]$', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32963296-f5b0-4b79-9065-ba92459bf259",
   "metadata": {},
   "source": [
    "- closures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d28757ae-27ee-47e7-bd8d-bc5eda0a0bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'i', 'ie', 'in', 'inn', 'm', 'me', 'mi', 'min', 'mine', 'n', 'ne', 'nee']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One or more 'ha'\n",
    "[w for w in wordlist if re.search(r'^[ha]+$', w)]\n",
    "\n",
    "# Zero or more\n",
    "[w for w in wordlist if re.search(r'^m*i*n*e*$', w)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8f82f-97df-4f82-a532-4c95cf90a392",
   "metadata": {},
   "source": [
    "- negations in sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf62a66-fc72-4efe-b936-7426ed7bc416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b',\n",
       " 'by',\n",
       " 'byth',\n",
       " 'c',\n",
       " 'cly',\n",
       " 'cry',\n",
       " 'crypt',\n",
       " 'cwm',\n",
       " 'cyp',\n",
       " 'cyst',\n",
       " 'd',\n",
       " 'dry',\n",
       " 'dryly',\n",
       " 'dryth',\n",
       " 'f',\n",
       " 'fly',\n",
       " 'fry',\n",
       " 'fyrd',\n",
       " 'g',\n",
       " 'glycyl',\n",
       " 'glyph',\n",
       " 'grr',\n",
       " 'gym',\n",
       " 'gyn',\n",
       " 'gyp',\n",
       " 'gyps',\n",
       " 'gypsy',\n",
       " 'gypsyfy',\n",
       " 'gypsyry',\n",
       " 'h',\n",
       " 'hymn',\n",
       " 'hyp',\n",
       " 'j',\n",
       " 'jynx',\n",
       " 'k',\n",
       " 'kyl',\n",
       " 'l',\n",
       " 'llyn',\n",
       " 'ly',\n",
       " 'lymph',\n",
       " 'lymphy',\n",
       " 'lynch',\n",
       " 'lynx',\n",
       " 'lys',\n",
       " 'm',\n",
       " 'my',\n",
       " 'myrrh',\n",
       " 'myrrhy',\n",
       " 'myst',\n",
       " 'myth',\n",
       " 'n',\n",
       " 'nth',\n",
       " 'nymph',\n",
       " 'nymphly',\n",
       " 'p',\n",
       " 'phytyl',\n",
       " 'ply',\n",
       " 'pry',\n",
       " 'pst',\n",
       " 'psych',\n",
       " 'pygmy',\n",
       " 'pyr',\n",
       " 'pyrryl',\n",
       " 'pyx',\n",
       " 'q',\n",
       " 'r',\n",
       " 'rhymy',\n",
       " 'rhythm',\n",
       " 'rynd',\n",
       " 'rynt',\n",
       " 's',\n",
       " 'scry',\n",
       " 'scyt',\n",
       " 'sh',\n",
       " 'shy',\n",
       " 'shyly',\n",
       " 'sky',\n",
       " 'sly',\n",
       " 'slyly',\n",
       " 'smyth',\n",
       " 'sny',\n",
       " 'spry',\n",
       " 'spryly',\n",
       " 'spy',\n",
       " 'st',\n",
       " 'strych',\n",
       " 'sty',\n",
       " 'styryl',\n",
       " 'sylph',\n",
       " 'sylphy',\n",
       " 'symphysy',\n",
       " 'sync',\n",
       " 'synch',\n",
       " 'syrt',\n",
       " 'syzygy',\n",
       " 't',\n",
       " 'tch',\n",
       " 'tck',\n",
       " 'th',\n",
       " 'thy',\n",
       " 'thymy',\n",
       " 'thymyl',\n",
       " 'try',\n",
       " 'tryp',\n",
       " 'tryst',\n",
       " 'tryt',\n",
       " 'tst',\n",
       " 'tyddyn',\n",
       " 'tyg',\n",
       " 'tymp',\n",
       " 'tynd',\n",
       " 'typp',\n",
       " 'typy',\n",
       " 'tyt',\n",
       " 'v',\n",
       " 'w',\n",
       " 'why',\n",
       " 'wry',\n",
       " 'wryly',\n",
       " 'wy',\n",
       " 'wyn',\n",
       " 'wynd',\n",
       " 'wynn',\n",
       " 'wyss',\n",
       " 'x',\n",
       " 'xylyl',\n",
       " 'xyst',\n",
       " 'y',\n",
       " 'ym',\n",
       " 'yn',\n",
       " 'yr',\n",
       " 'z']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-vowels\n",
    "[w for w in wordlist if re.search(r'^[^aeiouAEIOU]+$', w)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a1c1b3-8cd4-44e0-9426-147aadfce193",
   "metadata": {},
   "source": [
    "- extracting and counting word pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dbf0511-e031-4b08-8554-33211e3f74fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall(r'[aeiou]', word)      # all vowels\n",
    "len(re.findall(r'[aeiou]{2,}', word))  # sequences of 2+ vowels\n",
    "\n",
    "# Conditional frequency distribution (example: Rotokas CV pairs)\n",
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')\n",
    "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cfd = nltk.ConditionalFreqDist(cvs)\n",
    "cfd.tabulate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d2fec-8d04-4b83-99a3-5bd18e56b36a",
   "metadata": {},
   "source": [
    "- NLTK stemmers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dab28766-0705-4e5f-9fe7-fdf06f5414c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den',\n",
       " ':',\n",
       " 'list',\n",
       " ',',\n",
       " 'strange',\n",
       " 'wom',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'bas',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'suprem',\n",
       " 'execut',\n",
       " 'pow',\n",
       " 'der',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mand',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'som',\n",
       " 'farc',\n",
       " 'aqu',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "[porter.stem(t) for t in tokens]\n",
    "[lancaster.stem(t) for t in tokens]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca920b-3ef8-4c75-ba10-44c86ac3d7dd",
   "metadata": {},
   "source": [
    "4. Lemmeatization\n",
    " - only produces valid dictionary forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06ae94fb-e2ae-42c3-9e6e-f1307957b1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'woman',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distributing',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basis',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'government',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'executive',\n",
       " 'power',\n",
       " 'derives',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "[wnl.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e917b6d2-82bd-4b49-91e6-de6b08bdf58c",
   "metadata": {},
   "source": [
    "5. searching in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35bca980-cdca-4cfc-8a4d-669278fdf145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "brave; brave; brave\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    "moby = Text(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))\n",
    "\n",
    "# Pattern search\n",
    "moby.findall(r\"<a> (<.*>) <man>\")  # extract adjectives before 'man'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f19ca7f-be70-4cf0-ad09-49cc7cf18ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rule bro; telling you bro; u twizted bro\n",
      "lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la\n",
      "la la; lovely lol lol love; lol lol lol.; la la la; la la la\n"
     ]
    }
   ],
   "source": [
    "chat = Text(nltk.corpus.nps_chat.words())\n",
    "chat.findall(r\"<.*> <.*> <bro>\")  # phrases ending with 'bro'\n",
    "chat.findall(r\"<l.*>{3,}\")        # 3+ consecutive words starting with 'l'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a5148-cdb9-4098-a73f-0efd6e0f00e0",
   "metadata": {},
   "source": [
    "6. Key Tips\n",
    "\n",
    "Use raw strings r'' to avoid escaping issues (\\b, \\d, etc.).\n",
    "\n",
    "Regex greediness: * and + are greedy; use *? or +? for non-greedy matches.\n",
    "\n",
    "Regex can be used for:\n",
    "\n",
    "Word matching & extraction\n",
    "\n",
    "Stemming / suffix stripping\n",
    "\n",
    "Token normalization\n",
    "\n",
    "Corpus pattern search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69680db8-a638-4caf-83f4-2aff10a7e48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"humanity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfd27898-63ce-4873-adb4-e7ef5813d7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hum'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster.stem(\"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2cdb5-3320-41fa-8b03-1ec59384e4db",
   "metadata": {},
   "source": [
    "# list comprehension \n",
    "List comprehension in Python offers a concise and efficient way to create new lists based on existing iterables (like lists, tuples, or ranges). It provides a more compact and often more readable alternative to traditional for loops for list creation, transformation, and filtering.\n",
    "\n",
    "\n",
    "syntax : \n",
    "\n",
    "new_list = [expression for item in iterable]\n",
    "\n",
    "- expression: This defines how each item from the iterable will be transformed or used to create an element in the new_list.\n",
    "- item: This is a variable that takes on the value of each element from the iterable during the iteration.\n",
    "- iterable: This is the source sequence (e.g., a list, tuple, string, or range) that the list comprehension will iterate over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc41ee0-5d4e-4852-a5f3-727bed8a574a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
