{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac91e2ed-928d-4e98-8352-a307dcc6b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0696e-24e6-46de-b895-791e354228cc",
   "metadata": {},
   "source": [
    "# 6 Text Classification \n",
    "- Detecting patterns is a central part of Natural Language Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca11b8a-3b09-4579-a95d-b8353f4bf0f4",
   "metadata": {},
   "source": [
    "# 1 Supervised Classification \n",
    "\n",
    "- Classification is the task of choosing the correct class label for a given input.\n",
    "- In basic classification tasks, each input is considered in isolation from all other inputs, and the set of labels is defined in advance. Some examples of classification tasks are:\n",
    "\n",
    "    - Deciding whether an email is spam or not.\n",
    "    - Deciding what the topic of a news article is, from a fixed list of topic areas such as \"sports,\" \"technology,\" and \"politics.\"\n",
    "    - Deciding whether a given occurrence of the word bank is used to refer to a river bank, a financial institution, the act of tilting to the side, or the act of depositing something in a financial institut\n",
    "\n",
    "- A classifier is called supervised if it is built based on training corpora containing the correct label for each input\n",
    "-  During training, a feature extractor is used to convert each input value to a feature set. These feature sets, which capture the basic information about each input that should be used to classify it.\n",
    "-   Feature names are case-sensitive strings that typically provide a short human-readable description of the feature, as in the example 'last_letter'.\n",
    "-   Feature values are values with simple types, such as booleans, numbers, and strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c96bfe3-0975-43ef-9ec1-ec81000017d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EX gender classification\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b77f70a-8999-4366-81e5-2051c5e0b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])\n",
    "import random\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d34b9f8-cc5f-4601-ac24-21376f08bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79c7084d-241b-4ff2-8371-6df4dc005952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Neo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f607a-7f4b-4b29-8a8c-aec764525f8a",
   "metadata": {},
   "source": [
    "## 1.2   Choosing The Right Features\n",
    "- Selecting relevant features and deciding how to encode them for a learning method can have an enormous impact on the learning method's ability to extract a good model.\n",
    "- Much of the interesting work in building a classifier is deciding what features might be relevant, and how we can represent them.\n",
    "- Although it's often possible to get decent performance by using a fairly simple and obvious set of features, there are usually significant gains to be had by using carefully constructed features based on a thorough understanding of the task at hand.\n",
    "\n",
    "- using too many features in feautre encoding can lead to overfitting\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b42a96-058f-4fc0-8e70-91a0099d7798",
   "metadata": {},
   "source": [
    "## 1.5 Exploiting context'\n",
    "- By augmenting the feature extraction function, we could modify this part-of-speech tagger to leverage a variety of other word-internal features, such as the length of the word, the number of syllables it contains, or its prefix.\n",
    "- However, as long as the feature extractor just looks at the target word, we have no way to add features that depend on the context that the word appears in\n",
    "- But contextual features often provide powerful clues about the correct tag â€” for example, when tagging the word \"fly,\" knowing that the previous word is \"a\" will allow us to determine that it is functioning as a noun, not a verb.\n",
    "- Instead of just passing in the word to be tagged, we will pass in a complete (untagged) sentence\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2295f-8a13-4751-8659-f87b38dcd54c",
   "metadata": {},
   "source": [
    "## 1.6 Sequence Classification\n",
    "- In order to capture the dependencies between related classification tasks, we can use joint classifier models,\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c3c73d-5cbb-47b2-9431-005c73b49bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
